{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    " dev = \"cuda:0\" \n",
    "else: \n",
    " dev = \"cpu\" \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HazelNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # wof√ºr ist das da?\n",
    "        super(HazelNet, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "  \n",
    "        # over-write the first conv layer to be able to read images\n",
    "        # as resnet18 reads (3,x,x) where 3 is RGB channels\n",
    "        # whereas MNIST has (1,x,x) where 1 is a gray-scale channel\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        self.fc_in_features = self.resnet.fc.in_features \n",
    "        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n",
    "        self.resnet = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "        #self.resnet.fc kann das letzte layer ansprechen und ersetzen bei bedarf\n",
    "\n",
    "        # add linear layers to compare between the features of the two images\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.fc_in_features, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(1024, 128),\n",
    "            )        \n",
    "       \n",
    "        # initialize the weights\n",
    "        self.resnet.apply(self.init_weights)\n",
    "        self.fc.apply(self.init_weights)   \n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    # Erstellt NN mit dem input, inputs ist unser batch\n",
    "    def forward_once(self, inputs):\n",
    "        output = self.resnet(inputs)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    \n",
    "    def distance_layer(self, vec1, vec2):\n",
    "        cos = torch.nn.CosineSimilarity()\n",
    "        similarity = cos(vec1, vec2) \n",
    "        return similarity\n",
    "\n",
    "    def forward(self, template, img):\n",
    "        output1 = self.forward_once(template)\n",
    "        output2 = self.forward_once(img)\n",
    "\n",
    "        output = self.distance_layer(output1,output2)\n",
    " \n",
    "        return output   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "hidden_dim2 = 64\n",
    "hidden_dim3 = 32\n",
    "\n",
    "do_learn = True\n",
    "save_frequency = 2\n",
    "batch_size = 40 if torch.cuda.is_available() else 64\n",
    "\n",
    "learning_rate = 0.005\n",
    "num_epochs = 100\n",
    "weight_decay = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "loss_history = []\n",
    "r2_history = []\n",
    "\n",
    "\n",
    "loss_history2 = []\n",
    "r2_history2 = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Train, Val and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"images.npy\", allow_pickle=True ).astype(float)\n",
    "pairs = np.load(\"imagePairs.npy\", allow_pickle=True ).astype(int)\n",
    "labels = np.load(\"imageLabels.npy\", allow_pickle=True ).astype(float)\n",
    "\n",
    "pairs = pairs[500:3500]\n",
    "labels = labels[500:3500]\n",
    "\n",
    "# Split into Train, Val and Test\n",
    "rndidx = np.random.choice(np.arange(0,  len(pairs)), size = len(pairs) )\n",
    "trainidx, remain = np.array_split(rndidx, [int(0.7 * len(rndidx))])\n",
    "validx, testidx = np.array_split(remain, [int(0.5 * len(remain))])\n",
    "\n",
    "trainpairs = pairs[trainidx]\n",
    "valpairs = pairs[validx]\n",
    "testpairs = pairs[testidx]\n",
    "\n",
    "trainlabels = labels[trainidx]\n",
    "vallabels = labels[validx]\n",
    "testlabels = labels[testidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(vallabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for creating a Dataset which the dataloader from pytroch needs to create a wrapper for iterating though the data\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root, pairs, labels, images):\n",
    "       self.pairs = pairs\n",
    "       self.labels = labels\n",
    "       self.images = images\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        element = self.pairs[idx]\n",
    "        label = self.labels[idx]\n",
    "        template = self.images[self.pairs[idx][0]]\n",
    "        img = self.images[self.pairs[idx][1]]\n",
    "\n",
    "        template, img = resize(template, (224, 224)), resize(img, (224, 224,))\n",
    "\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        template = np.expand_dims(template, axis=0)\n",
    "       \n",
    "\n",
    "        return  template.astype(np.float32), img.astype(np.float32), label.astype(np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HazelNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_data = CustomImageDataset(\"\", pairs=trainpairs, labels=trainlabels, images=images)\n",
    "val_data = CustomImageDataset(\"\",  pairs=valpairs, labels=vallabels, images=images)\n",
    "test_data = CustomImageDataset(\"\", pairs=testpairs, labels=testlabels, images=images)\n",
    "\n",
    "# Create data loaders.\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0\n",
    "    running_mse = 0\n",
    "    running_r2 = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_r2 = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        templates, images, targets = data\n",
    "        \n",
    "        templates = templates.to(device)\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(templates, images)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        rscore = r2score(outputs, torch.tensor(targets).squeeze())\n",
    "        running_r2 += rscore\n",
    "        total_r2 += rscore\n",
    "\n",
    "        mse = msecalc(outputs, torch.tensor(targets).squeeze())\n",
    "        running_mse += mse\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 80:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tR2Score: {} \\tMSE: {}'.format(\n",
    "            epoch_index, batch_idx * len(templates), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), running_mse / 100, running_r2 / 100, running_mse / 100 ))\n",
    "            running_loss = 0\n",
    "            running_mse = 0\n",
    "            running_r2 = 0\n",
    "\n",
    "    avg_loss = total_loss / (batch_idx + 1)\n",
    "    avg_r2 = total_r2 / (batch_idx + 1)   \n",
    "\n",
    "    del templates\n",
    "    del images\n",
    "    del targets\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return avg_loss, avg_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.train(False) <- Ich wei√ü nicht warum, aber das hier sorgt daf√ºr, dass die Werte imme rauf 1.0 predicted werden f√ºr die validation daten. Zumindest in den ersten 20 epochen\n",
    "\n",
    "with torch.no_grad():\n",
    "     print(model(vtemplates,vimages))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (num_epochs):\n\u001b[0;32m      9\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m     avg_loss, avg_r2 \u001b[39m=\u001b[39m train_one_epoch(epoch)\n\u001b[0;32m     11\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[0;32m     12\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [13], line 18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch_index)\u001b[0m\n\u001b[0;32m     14\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[39m=\u001b[39m model(templates, images)\n\u001b[0;32m     20\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     21\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [6], line 55\u001b[0m, in \u001b[0;36mHazelNet.forward\u001b[1;34m(self, template, img)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, template, img):\n\u001b[1;32m---> 55\u001b[0m     output1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_once(template)\n\u001b[0;32m     56\u001b[0m     output2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_once(img)\n\u001b[0;32m     58\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_layer(output1,output2)\n",
      "Cell \u001b[1;32mIn [6], line 43\u001b[0m, in \u001b[0;36mHazelNet.forward_once\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_once\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m---> 43\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresnet(inputs)\n\u001b[0;32m     44\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mview(output\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(output)\n",
      "File \u001b[1;32mc:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:151\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrack_running_stats:\n\u001b[0;32m    149\u001b[0m     \u001b[39m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_batches_tracked\u001b[39m.\u001b[39;49madd_(\u001b[39m1\u001b[39;49m)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    152\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# use cumulative moving average\u001b[39;00m\n\u001b[0;32m    153\u001b[0m             exponential_average_factor \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "tb = SummaryWriter()\n",
    "best_vloss = 1000000\n",
    "msecalc = torchmetrics.MeanSquaredError().to(device)\n",
    "r2score = torchmetrics.R2Score().to(device)\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "\n",
    "    model.train(True)\n",
    "    avg_loss, avg_r2 = train_one_epoch(epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0\n",
    "    running_vmse = 0\n",
    "    running_vr2 = 0\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vtemplates, vimages, vtargets = vdata\n",
    "            vtemplates = vtemplates.to(device)\n",
    "            vimages = vimages.to(device)\n",
    "            vtargets = vtargets.to(device)\n",
    "\n",
    "            voutputs = model(vtemplates,vimages)\n",
    "            vloss =  criterion(voutputs, vtargets)\n",
    "            running_vloss += vloss.item()\n",
    "\n",
    "            vrscore = r2score(voutputs, torch.tensor(vtargets).squeeze())\n",
    "            running_vr2 += vrscore\n",
    "\n",
    "            vmse = msecalc(voutputs, torch.tensor(vtargets).squeeze())\n",
    "            running_vmse += vmse\n",
    "            print(f\"Berechneter Loss f√ºr VALIDATION {vloss.item()} Total loss aktuell {running_vloss}, voutputs ist: {voutputs}\")\n",
    "       \n",
    "        avg_vloss = running_vloss / (i+1)\n",
    "        avg_vr2 = running_vr2  / (i+1)\n",
    "        avg_vmse = running_vmse / (i+1)\n",
    "\n",
    "        print('EPOCH RESULTS: Train Loss {} Valid Loss {} Train R2 {} Valid R2 {} '.format(avg_loss, avg_vloss, avg_r2, avg_vr2))\n",
    "      #  print('EPOCH RESULTS: Train Loss {0:.{1}f} Valid Loss {2} Train R2 {3} Valid R2 {0} '.format(avg_loss, avg_vloss, avg_r2, avg_vr2))\n",
    "\n",
    "        tb.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss},\n",
    "                        epoch + 1)\n",
    "\n",
    "\n",
    "        tb.add_scalars('Training vs. Validation R2',\n",
    "                        { 'Training' : avg_r2, 'Validation' : avg_vr2},\n",
    "                        epoch + 1)\n",
    "        tb.flush()       \n",
    "\n",
    "\n",
    "    #Track best performance, and save the model's state\n",
    "        #if avg_vloss < best_vloss:\n",
    "         #   best_vloss = avg_vloss\n",
    "          #  torch.save(model.state_dict(), \"bestmodel2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10,50):\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.suptitle(trainlabels[i])\n",
    "    ax[0].imshow(images[trainpairs[i][0]])\n",
    "    ax[1].imshow(images[trainpairs[i][1]])\n",
    "    #print(labelTest[i])\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HazelNetTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HazelNet().to(device)\n",
    "model.load_state_dict(torch.load(\"bestmodel2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (model, template, img):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ypred = model(template,img)\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:03,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for i,data in tqdm(enumerate(test_loader)):\n",
    "  templates, images, targets = data\n",
    "  templates = templates.to(device)\n",
    "  images = images.to(device)\n",
    "  targets = targets.to(device)\n",
    "  labels.extend(targets)\n",
    "  predictions.extend(predict(model = model, template = templates, img = images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10,50):\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.suptitle(trainlabels[i])\n",
    "    ax[0].imshow(images[trainpairs[i][0]])\n",
    "    ax[1].imshow(images[trainpairs[i][1]])\n",
    "    #print(labelTest[i])\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UKSH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bcfe374eb6962dfaa81be4d9965aebe0aa9e8512cbd375dd90ce444d679a914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
