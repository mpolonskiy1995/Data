{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\Envs\\UKSH\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from random import randrange\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" \n",
    "device = torch.device(dev) \n",
    "\n",
    "size = (150,150)\n",
    "\n",
    "path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing\n",
    "### Calculating mean and std of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "convert = transforms.Compose([   \n",
    "\n",
    "    transforms.Grayscale(),\n",
    "    # resize\n",
    "    transforms.Resize(size),\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    \n",
    "])\n",
    "\n",
    "for filename in os.listdir(\"testimages\"):\n",
    "    img = Image.open(f\"testimages/{filename}\").convert('RGB')\n",
    "    img = convert(img)\n",
    "    imgs.append(img)\n",
    "imgs = torch.stack(imgs)\n",
    "\n",
    "imgs_mean = imgs.mean()\n",
    "imgs_std = imgs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "\n",
    "    transforms.Grayscale(),\n",
    "    # resize\n",
    "    transforms.Resize(size),\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "    # normalize\n",
    "    transforms.Normalize((imgs_mean), (imgs_std))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HazelNet(nn.Module):\n",
    "    \"\"\"Class for instanciating the NN\n",
    "\n",
    "    Args:\n",
    "        nn (nn.Module): super class to inherit from in pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Cosntructor for initialization\n",
    "        \"\"\"\n",
    "        super(HazelNet, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "  \n",
    "        # over-write the first conv layer to be able to read images\n",
    "        # as resnet18 reads (3,x,x) where 3 is RGB channels\n",
    "        # whereas MNIST has (1,x,x) where 1 is a gray-scale channel\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        self.fc_in_features = self.resnet.fc.in_features \n",
    "        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n",
    "        self.resnet = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "        # add linear layers to compare between the features of the two images\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.fc_in_features, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.5),\n",
    "            nn.Linear(1024, 128),\n",
    "            )        \n",
    "       \n",
    "        # initialize the weights\n",
    "        self.resnet.apply(self.init_weights)\n",
    "        self.fc.apply(self.init_weights)   \n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        \"\"\"Function for weight init\n",
    "\n",
    "        Args:\n",
    "            m (module): module to use for init\n",
    "        \"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward_once(self, inputs):\n",
    "        \"\"\"Helper function for forward path\n",
    "\n",
    "        Args:\n",
    "            inputs (tensor): input tensor\n",
    "\n",
    "        Returns:\n",
    "            tensor: output tensor\n",
    "        \"\"\"\n",
    "        output = self.resnet(inputs)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "    def distance_layer(self, vec1, vec2):\n",
    "        \"\"\"Function for calculating the cosine similarity between two tensors\n",
    "\n",
    "        Args:\n",
    "            vec1 (tensor): tensor for template images\n",
    "            vec2 (tensor): tensor for images to compare with\n",
    "\n",
    "        Returns:\n",
    "            tensor: tensor containing the calculated similarity as float\n",
    "        \"\"\"\n",
    "        cos = torch.nn.CosineSimilarity()\n",
    "        similarity = cos(vec1, vec2) \n",
    "        return similarity\n",
    "\n",
    "    def forward(self, template, img):\n",
    "        \"\"\"Main function for forward path\n",
    "\n",
    "        Args:\n",
    "            template (tensor): tensor of template images\n",
    "            img (tensor): tensor of images to compare\n",
    "\n",
    "        Returns:\n",
    "            tensor: tensor containing the calculated similarity as float\n",
    "        \"\"\"\n",
    "        output1 = self.forward_once(template)\n",
    "        output2 = self.forward_once(img)\n",
    "        output = self.distance_layer(output1,output2)\n",
    " \n",
    "        return output\n",
    "\n",
    "    def readImg_url (self, url1, url2, iswhite = False, plot = False):\n",
    "        \"\"\"Function for reading images into processable tensors. Can draw a picture of processed images\n",
    "\n",
    "        Args:\n",
    "            url1 (string): url to template image\n",
    "            url2 (string): url to image for comparison\n",
    "            iswhite (bool, optional): inverts image colors if set to true. Defaults to False.\n",
    "            plot (bool, optional): plots imported images if set to true. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            tensor, tensor: two tensors containing the processed images ready for prediction\n",
    "        \"\"\"\n",
    "        # invert white and black if image is on white background\n",
    "        if iswhite:\n",
    "            realim1 = cv.bitwise_not(cv.imread(url1,0)).astype(np.float32)\n",
    "            realim2 = cv.bitwise_not(cv.imread(url2,0)).astype(np.float32)\n",
    "        else: \n",
    "            realim1 = cv.imread(url1,0).astype(np.float32)\n",
    "            realim2 = cv.imread(url2,0).astype(np.float32)\n",
    "\n",
    "        realim1 =  cv.resize(realim1, imgsize)\n",
    "        realim2 =  cv.resize(realim2, imgsize)\n",
    "        template = torch.tensor(realim1).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        img = torch.tensor(realim2.astype(np.float32)).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            ax[0].imshow(realim1)\n",
    "            ax[1].imshow(realim2)\n",
    "        return template, img        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HazelNet().to(device)\n",
    "#torch.save(model.state_dict(), f\"test\")\n",
    "model.load_state_dict(torch.load(f\"bestmodel_area\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>template</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>HazelArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>images\\lost.png</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                img         template  label  pred  HazelArea\n",
       "0   images\\lost.png  images\\lost.png    0.6   0.0        NaN\n",
       "1   images\\lost.png  images\\lost.png  576.0   0.0        NaN\n",
       "2   images\\lost.png  images\\lost.png    0.6   0.0        NaN\n",
       "3   images\\lost.png  images\\lost.png    0.6   0.0        NaN\n",
       "4   images\\lost.png  images\\lost.png    0.6   0.0        NaN\n",
       "5   images\\lost.png  images\\lost.png    0.6   0.0        NaN\n",
       "6   images\\lost.png  images\\lost.png    0.7   0.0        NaN\n",
       "7   images\\lost.png  images\\lost.png    0.6   1.0        NaN\n",
       "8   images\\lost.png  images\\lost.png    0.6   1.0        NaN\n",
       "9   images\\lost.png  images\\lost.png    0.6   1.0        NaN\n",
       "10  images\\lost.png  images\\lost.png    0.7   1.0        NaN\n",
       "11  images\\lost.png  images\\lost.png    0.6   1.0        NaN\n",
       "12  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "13  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "14  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "15  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "16  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "17  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "18  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "19  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "20  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "21  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "22  images\\lost.png  images\\lost.png    0.7   NaN        1.0\n",
       "23  images\\lost.png  images\\lost.png    0.7   NaN        1.0\n",
       "24  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "25  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "26  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "27  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "28  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "29  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "30  images\\lost.png  images\\lost.png    0.6   NaN        1.0\n",
       "31  images\\lost.png  images\\lost.png    0.7   NaN        1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"Flask-Tests/logging\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UKSH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bcfe374eb6962dfaa81be4d9965aebe0aa9e8512cbd375dd90ce444d679a914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
